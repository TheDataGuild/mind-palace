<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scalable Neural Decoder for Topological Surface Codes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-02-24">24 February 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kai</forename><surname>Meinerz</surname></persName>
							<idno type="ORCID">0000-0002-9141-7113</idno>
						</author>
						<author>
							<persName><forename type="first">Chae-Yeun</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Trebst</surname></persName>
						</author>
						<author>
							<affiliation>
								<orgName>Institute for Theoretical Physics, University of Cologne,</orgName>
								<address><addrLine>50937 Cologne, Germany</addrLine></address>
							</affiliation>
						</author>
						<title level="a" type="main">Scalable Neural Decoder for Topological Surface Codes</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-24">24 February 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1103/PhysRevLett.128.080505</idno>
					<note type="submission">Received 5 February 2021; revised 21 December 2021; accepted 2 February 2022;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-10-09T23:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the advent of noisy intermediate-scale quantum (NISQ) devices, practical quantum computing has seemingly come into reach. However, to go beyond proof-of-principle calculations, the current processing architectures will need to scale up to larger quantum circuits which will require fast and scalable algorithms for quantum error correction. Here, we present a neural network based decoder that, for a family of stabilizer codes subject to depolarizing noise and syndrome measurement errors, is scalable to tens of thousands of qubits (in contrast to other recent machine learning inspired decoders) and exhibits faster decoding times than the state-of-the-art union find decoder for a wide range of error rates (down to 1%).</p><p>The key innovation is to autodecode error syndromes on small scales by shifting a preprocessing window over the underlying code, akin to a convolutional neural network in pattern recognition approaches. We show that such a preprocessing step allows to effectively reduce the error rate by up to 2 orders of magnitude in practical applications and, by detecting correlation effects, shifts the actual error threshold up to fifteen percent higher than the threshold of conventional error correction algorithms such as union find or minimum weight perfect matching, even in the presence of measurement errors. An in situ implementation of such a machine learning-assisted quantum error correction will be a decisive step to push the entanglement frontier beyond the NISQ horizon.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Introduction.-In quantum computing, recent years have seen a paradigm shift which has pivoted experimental road maps from building devices of a few pristine qubits toward the realization of circuit architectures of 50-100 qubits but tolerating a significant level of imperfections-the advent of what has been termed noisy intermediate-scale quantum (NISQ) technology <ref type="bibr" target="#b0">[1]</ref>. This move has enabled a fundamental success in the recent demonstration that such a NISQ quantum processor is capable of exhibiting a true "quantum advantage" over classical computing resources <ref type="bibr" target="#b1">[2]</ref>. One of the leading NISQ platforms involves arrays of transmons, superconducting charge qubits <ref type="bibr" target="#b2">[3]</ref>, which by design are particularly resilient with regard to charge fluctuations. However, building larger quantum circuits from transmons comes with some intricate challenges <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> and will eventually mandate to incorporate quantum error correction (QEC) schemes <ref type="bibr" target="#b5">[6]</ref>. Arguably the most promising approach here is the implementation of a surface code <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, which exploits topological properties of the system and, at the same time, remains experimentally feasible <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. In practical settings, one downside of realizing such surface code architectures is the relatively slow decoding time of current quantum error correction codes.</p><p>The decoding step in quantum error correcting codes requires, at its core, a classical algorithm that efficiently infers the locations of errors from measured error syndromes <ref type="bibr" target="#b10">[11]</ref>. The most widely adopted algorithm for this purpose is minimum weight perfect matching (MWPM) <ref type="bibr" target="#b11">[12]</ref>, an algorithm which runs in polynomial time and is known to nearly achieve the optimal threshold for the independent noise model <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. One of the drawbacks of the MWPM algorithm, however, is that its implementations are often simply too slow. To improve algorithmic scaling and to push error thresholds also for more general noise situations, a number of alternative decoding approaches have been suggested, of which the most notable might be the renormalization group (RG) <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref> and union-find (UF) <ref type="bibr" target="#b17">[18]</ref> decoders. The RG decoder runs, for a surface code in a two-dimensional (2D) geometry of linear size L, in OðL 2 log LÞ time, often a significant improvement over the MWPM approach [which, in the worst case, scales cubic in the number of errors, i.e., OðL 6 Þ in code distance]. However, its threshold value of ∼0.129 for depolarizing noise <ref type="bibr" target="#b14">[15]</ref> is lower than that of the MWPM algorithm (∼0.151 <ref type="bibr" target="#b13">[14]</ref>). The most efficient conventional algorithm is the UF decoder which runs in O½L 2 αðL 2 Þ, i.e., almost linear in the number of qubits <ref type="bibr" target="#b18">[19]</ref>, with a threshold ∼0.146 for the depolarizing noise model (see below). In addition, the last two years have seen a flurry of activity to adopt machine learning (ML) techniques to best the decoding times and threshold values of these "conventional" algorithms <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b23">[23]</ref><ref type="bibr" target="#b24">[24]</ref><ref type="bibr" target="#b25">[25]</ref><ref type="bibr" target="#b26">[26]</ref><ref type="bibr" target="#b27">[27]</ref><ref type="bibr" target="#b28">[28]</ref><ref type="bibr" target="#b29">[29]</ref><ref type="bibr" target="#b30">[30]</ref><ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref>. As ML methods can be easily parallelized and generally offer a high degree of adaptability, one might easily accept their potential, but the first practical ML-based decoders typically delivered only on one of the two benchmarksimproving the error threshold at the expense of scalability or the other way round, providing good scalability but leading to error thresholds which are sometimes even below those of the conventional algorithms <ref type="bibr" target="#b34">[34]</ref>.</p><p>It is the purpose of this Letter to introduce a powerful two-step decoding algorithm that combines neural network based preprocessing and union-find decoding to simultaneously achieve (i) improved error thresholds for depolarizing noise (even in the presence of syndrome measurement errors), (ii) algorithmic scalability up to tens of thousands of qubits, and (iii) real-life wall-clock run times (i.e., the elapsed time passed to execute the decoding process) that, for a range of error rates, best even those of the bare union-find algorithm. Our main algorithmic idea can be described as a hierarchical approach <ref type="bibr" target="#b33">[33]</ref> that employs an ML decoder to preprocess local error corrections and leave the unresolved longer-range errors to a conventional UF decoding. The preprocessing step shifts a 2D subsystem over a given stabilizer code (akin to the preprocessing in a convolutional neural network) and decodes local errors in these subsystems. After this step, the system still exhibits errors that require longer range corrections, for which we employ a conventional UF decoder. However, since the preprocessing reduces the effective error rate-up to 2 orders of magnitude depending on the original error rate-this second step is extremely performant as compared to, e.g., employing UF decoding to the original unprocessed error instances. Extensive wallclock time measurements of our approach (the true performance indicator in many real-life applications) show that our algorithm outperforms the bare UF decoder in a noise regime from 1% (in which one might want to operate quantum computing devices) up to the 10% regime where our ML-assisted approach is found to push the error threshold by some 15 % above the value of the bare UF decoder, as summarized in Table <ref type="table">I</ref>. Our approach bears some similarity to the "lazy UF decoder" <ref type="bibr" target="#b33">[33]</ref>, which employs hierarchical decoding with a strictly local, hard decision preprocessing step and has been shown to substantially improve UF decoding for ultralow error rates below the per mil range.</p><p>Hierarchical QEC.-Throughout the Letter, we apply our decoding algorithm to the toric code in the presence of depolarizing noise as well as a scenario with additional syndrome measurement errors. For the latter, we use a phenomenological noise model where ancilla qubits for measuring syndromes are also subject to depolarizing noise but propagation of errors between data and ancilla qubits is neglected. The toric code is defined on a square lattice of linear size L and the stabilizer operators around the vertices and plaquettes are given by X</p><formula xml:id="formula_0">v ¼ Q i∈v X i and Z p ¼ Q i∈p Z i .</formula><p>The code space is then spanned by the basis vectors fjψi∶X v jψi ¼ 1 ∀ v; Z p jψi ¼ 1 ∀ pg, which, for periodic boundary conditions, is four dimensional (and thus encodes two qubits) and the distance of the code is L. Each Z (X) error on a qubit flips the value of the nearby X v (Z p ) operators.</p><p>The decoding problem is then defined as identifying the error configuration for a given syndrome, i.e., a given measurement of the outcomes of all stabilizers X v and Z p . To do so, we employ a two-step hierarchical procedure. In the first stage-the ML-assisted preprocessing-we aim to remove those errors that can be inferred from local syndromes. To this end, we only consider qubits directly connected to so-called defects (identified by an odd syndrome measurement X v ¼ -1 or Z p ¼ -1), as they are the typical source of locally correctable errors. To infer which error is the most probable for a given qubit, our preprocessing step shifts through all qubits with a subsystem of size l × l centered around an "examination qubit" located at its center (see the setup in Fig. <ref type="figure">1</ref>). The local inference task for each such examination qubit is then assigned to a neural network, whose details we TABLE I. Overview of results. For multiple variants of our decoding algorithm we provide the error threshold p th (second column) for depolarizing noise (upper panel) and additional syndrome measurement errors (lower panel) where ancillary qubits for measuring syndromes are also subject to depolarizing noise, as well as wall-clock time measurements (in milliseconds) of the decoding time for different error rates (averaged over 10 6 instances) for code distances L ¼ 255 and L ¼ 31, respectively. The boldfaced entries identify the best performing algorithm when optimizing for error threshold or compute times. Comparisons are shown for the union-find (UF) and minimum weight perfect matching (MWPM) decoders, combined with either lazy <ref type="bibr" target="#b33">[33]</ref> or machine learning (ML) assisted preprocessing using subsystems of size l ¼ 3, 5, or 7 as indicated in brackets (see main text). We have used a custom implementation for the UF decoder <ref type="bibr" target="#b42">[42]</ref> and PyMatching <ref type="bibr" target="#b43">[43]</ref> for MWPM <ref type="bibr" target="#b44">[44]</ref>. In the presence of additional syndrome errors, the pure MWPM calculation was optimized by combining the Blossom and Dykstra algorithms and for the ML-assisted MWPM with precomputed shortest paths. Details of our hardware setup are given in Supplemental Material <ref type="bibr" target="#b34">[34]</ref>. The second stage of our algorithm is to process the remaining nonlocal errors. To do so, we employ a conventional UF decoder on the remaining syndrome. Doing so is significantly more efficient than employing the UF decoder on the bare decoding problem (without the preprocessing), as we will see that the "effective error rate" for this UF decoding step is up to 2 orders of magnitude smaller than the original error rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Neural decoder.-At the heart of our hierarchical QEC approach is a neural network that decodes error syndromes within a local subsystem, as illustrated in Fig. <ref type="figure">1</ref>. We train this neural network to output the most probable error (among the four possible fI; X; Y; Zg errors) of the central qubit given 2l 2 nearby syndromes as an input (with the factor of 2 coming from the two types of X and Z measurements). In machine learning, this type of task is commonly known as a multiclass classification problem and exceedingly well studied in the context of supervised learning approaches. To adopt such a supervised learning approach to optimize our neural network, we do training with a labeled dataset, i.e., batches of error-syndrome pairs generated for a given error rate (and noise model), training separate networks for each error rates. In practice, we train our networks in 10 6 epochs, for which we create independent sets of 512 error-syndrome batches "on the fly," which also reduces the chance of overfitting.</p><p>In designing the neural network (NN) architecture, there is an inherent trade-off between the two algorithmic layers of our hierarchical approach: If one opts for a small NN, its computation time remains low but its accuracy in resolving local syndromes drops, resulting in more computational load for the UF decoder on the higher algorithmic layer. If, on the other hand, one opts for a large NN, its accuracy in resolving syndromes goes up at the cost of larger compute times, while also alleviating the load of the higher-level UF decoder. Indeed, this trade-off leads to a sweet spot, i.e., an intermediate NN size that results, e.g., in minimal wallclock run times or maximal error thresholds. To identify an optimal configuration, we have explored a multitude of different network architectures for the case of depolarizing noise, varying the size of the subsystem, the depth of the network, and the number of nodes per layer as main parameters (as detailed in Supplemental Material <ref type="bibr" target="#b34">[34]</ref>). When optimizing for compute speed a 5 × 5 subsystem turns out to be ideal, while pushing the error threshold one might want to go with a 7 × 7 subsystem-see Table <ref type="table">I</ref>. However, since the error threshold of the speed-optimized network is only 3% smaller than the threshold-optimized network, we consider the 5 × 5 NN approach the best compromise in achieving fast decoding and high error thresholds for an algorithm that also delivers on high scalability.</p><p>Benchmark results.-In benchmarking our hierarchical QEC algorithm, we start in the high-noise regime and calculate the error threshold of our approach. Decoding 10 6 random instances of depolarizing noise for different error rates and linear system sizes in the range L ¼ 7; …; 127 we can readily deduce the error threshold from the finite-size scaling shown in Fig. <ref type="figure">2</ref>. In comparison to the bare UF FIG. <ref type="figure">1</ref>. Neural network setup. Syndromes in the immediate vicinity (red shading) of a reference qubit (cyan circle) are used as input, whereby measured syndromes (blue or yellow) are assigned the value þ1= -1 and no syndromes (gray) are assigned value 0, respectively. Passing the input through the feed forward network results in the error probabilities for the reference qubit. FIG. <ref type="figure">2</ref>. Error threshold and scaling behavior for the conventional union find (UF) algorithm (upper row), and the machine learning assisted ML þ UF algorithm (lower row) for depolarizing noise (left column) and additional syndrome errors (right column). algorithm (top panel), which exhibits an error threshold of p UF th ¼ 0.146ð1Þ, our algorithm yields a 10% higher value of 0.162( <ref type="formula">5</ref>) and an increase of more than 20% compared to the lazy UF decoder's threshold of 0.131(9) <ref type="bibr" target="#b45">[45]</ref>. This notable increase of the error threshold indicates that our ML-assisted approach is capable of identifying and resolving correlated errors in the depolarizing noise, which the bare UF decoder cannot handle. The strength of the ML-assisted decoder in the dense error regime can also be exemplified by the logical accuracy near the threshold plotted in Fig. <ref type="figure">3</ref>, which shows a higher logical accuracy for the ML þ UF decoder in this regime, independent of system size. It should further be noted that our threshold values are higher than the one of the bare RG decoder <ref type="bibr" target="#b14">[15]</ref> with p RG th ¼ 0.153 and comparable to those found for a combination of RG and sparse decoders <ref type="bibr" target="#b16">[17]</ref>, or the best ML-based decoders using deep neural networks, for which error thresholds of p ML th ≈ 0.165 are reported <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">28]</ref> for depolarizing noise. However, our result is still significantly below the optimal theoretical value <ref type="bibr" target="#b46">[46]</ref> of p opt ¼ 0.189ð3Þ. Performing a similar analysis for a scenario with additional syndrome measurement errors, we come to analogous conclusions with a spread of the error threshold between p th ¼ 0.031ð3Þ for the lazy UF decoder and 0.044(5) obtained for ML-assisted MWPM decoding (lower panel of Table <ref type="table">I</ref>).</p><p>One measure to illustrate the inner workings of our hierarchical approach is an "effective error rate," i.e., the reduction of errors obtained after performing the first ML-assisted step of our algorithm. Shown in Fig. <ref type="figure" target="#fig_0">4</ref>, this effective error rate reveals that preprocessing is particularly powerful at low error rates, i.e., in the regime where few long-range errors occur. Here, one can reduce the initial error rate by more than 2 orders of magnitude (see the right panel of Fig. <ref type="figure" target="#fig_0">4</ref>), thereby significantly speeding up the subsequent UF decoding step (as compared to a direct application to the original syndrome).</p><p>As such one might naively expect the biggest computing gain of our algorithm in the low-noise regime. For practical implementations this is, however, not true as becomes apparent when performing run-time measurements of our decoder. Such measurements are illustrated in Fig. <ref type="figure">5</ref> where the decoding time (again averaged over 10 6 error instances) is plotted versus the linear system size for different error rates. The top panel nicely demonstrates that, for large system sizes, we find near linear scaling for both the UF and our hierarchical UF þ ML decoder, independent of the error rate. Note that our ML-assisted decoder easily scales up to 2 × 255 × 255 ≈ 130 000 qubits where the decoding time per instance is still a fraction of a second-this should be contrasted to other ML-based decoders reported in the literature, which could not be scaled beyond a hundred qubits (see the overview in Supplemental Material <ref type="bibr" target="#b34">[34]</ref> Table <ref type="table">IV</ref>).</p><p>If we look at the scaling of our algorithm for small to moderate system sizes (highlighted in the lower panels of Fig. <ref type="figure">5</ref>), a breakdown of the linear scaling of the MLassisted decoder becomes evident. There is a considerable "lag" in our implementation, which arises from using an external graphics processing unit (GPU) to perform the preprocessing step (see Supplemental Material <ref type="bibr" target="#b34">[34]</ref> for hardware specifications). Doing so readily implies another inherent trade-off: initializing the neural network and loading the syndrome data to the GPU has almost constant overhead, which explains the plateau in our scaling plots for small system sizes where the advantage of GPU processing of the neural network is not compensating this overhead (as it does for large system sizes). We have measured this "kernel start-up" time to subtract this overhead-which would not exist in a dedicated or in situ device in a practical implementation of QEC in the lab-to arrive at the "kernel adjusted" scaling of Fig. <ref type="figure">5</ref>. The point at which the ML-assisted decoder outperforms the bare UF decoder comes down to code distances of L ≈ 31, but we FIG. <ref type="figure">3</ref>. Logical accuracy of the conventional UF decoder and combined with lazy or ML-assisted preprocessing for depolarizing noise. The inset shows the case of additional syndrome measurement errors. The ML þ UF decoder increases the logical accuracy, independent of system size, for all error rates shown. expect even smaller code distances to benefit from the ML-assisted approach when going for an in situ implementation <ref type="bibr" target="#b35">[35]</ref>, using field-programmable gate arrays or tensor processing units <ref type="bibr" target="#b36">[36]</ref>.</p><p>In summary, we have demonstrated that the combination of machine-learning assisted preprocessing in conjunction with conventional decoders in a newly devised hierarchical approach results in a vastly scalable algorithm. Our practical implementation shows that one can increase logical accuracy and push the error threshold by resolving correlated errors, while also reducing the actual decoding times (to a few milliseconds in our hardware setup) particularly in the dense error regime. As such our approach nicely complements the lazy UF decoder <ref type="bibr" target="#b33">[33]</ref> which excels in the opposite regime of ultralow error rates. Taken together, one might argue that one should always combine the UF decoder with some sort of preprocessing stepwhich one to go for depends on the expected noise level and code distances.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 4 .</head><label>4</label><figDesc>FIG.<ref type="bibr" target="#b3">4</ref>. Effective error reduction attained by the ML preprocessing step. Left: The effective error rate p eff as a function of the original error probability p err . The effective error rate is calculated from the number of remaining syndromes p eff ¼ P S i =ðð4=3Þ× 2 × 2L 2 Þ. Right: The ratio of original error probability and effective error rate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The results of the inference are collected and the respective corrections are applied in one shot at the end. The outcome of this step is that a large number of local errors are decoded and only a small fraction of nonlocal errors, manifest on scales beyond the range of our subsystem, remain.</figDesc><table><row><cell cols="2">PHYSICAL REVIEW LETTERS 128, 080505 (2022)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>discuss below.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>p th</cell><cell cols="4">t p¼0.01 t p¼0.05 t p¼0.1 t p¼0.1461</cell></row><row><cell></cell><cell cols="3">Depolarizing noise (L ¼ 255)</cell><cell></cell></row><row><cell>MLð7Þ þ UF</cell><cell cols="2">0.167ð0Þ 10.5</cell><cell>25.1</cell><cell>43.4</cell><cell>78.6</cell></row><row><cell>MLð5Þ þ UF</cell><cell cols="2">0.162(5) 6.7</cell><cell>12.8</cell><cell>26.2</cell><cell>56.2</cell></row><row><cell>Lazy þ UF</cell><cell cols="2">0.131(9) 6.9</cell><cell>20.7</cell><cell>51.1</cell><cell>Á Á Á</cell></row><row><cell>UF</cell><cell cols="2">0.146(1) 8.4</cell><cell>22.5</cell><cell>44.9</cell><cell>92.8</cell></row><row><cell cols="5">MLð7Þ þ MWPM 0.167(1) ∼210 ∼530 ∼650</cell><cell>∼980</cell></row><row><cell cols="5">MLð5Þ þ MWPM 0.163(8) ∼270 ∼510 ∼650</cell><cell>∼970</cell></row><row><cell>MWPM</cell><cell cols="5">0.154(2) ∼560 ∼840 ∼1100 ∼1300</cell></row><row><cell>Algorithm</cell><cell>p th</cell><cell cols="4">t p¼0.01 t p¼0.02 t p¼0.03 t p¼0.0378</cell></row><row><cell cols="5">Depolarizing noise þ syndrome errors (L ¼ 31)</cell></row><row><cell>MLð3Þ þ UF</cell><cell cols="2">0.043(4) 12.1</cell><cell>13.5</cell><cell>15.4</cell><cell>17.8</cell></row><row><cell>Lazy þ UF</cell><cell cols="2">0.031(3) 11.1</cell><cell>12.8</cell><cell>16.6</cell><cell>Á Á Á</cell></row><row><cell>UF</cell><cell cols="2">0.037(8) 11.5</cell><cell>13.4</cell><cell>15.7</cell><cell>18.9</cell></row><row><cell cols="3">MLð3Þ þ MWPM Ã 0.044ð5Þ 14.6</cell><cell>25.8</cell><cell>81.5</cell><cell>229</cell></row><row><cell>MWPM</cell><cell cols="2">0.043(7) 211</cell><cell>239</cell><cell>273</cell><cell>294</cell></row><row><cell>080505-2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We thank M. Kastoryano and T. Wagner  for insightful discussions, as well as O. Higgott for comments on optimizing the PyMatching results for MWPM decoding the phenomenological noise model. This project was funded by the Deutsche Forschungsgemeinschaft under Germany's Excellence Strategy-Cluster of Excellence Matter and Light for Quantum Computing (ML4Q) EXC 2004/1-390534769 and within the CRC network TR 183 (Project Grant No. 277101999) as part of project B01.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2018-08-06-79</idno>
		<title level="m">Quantum Computing in the NISQ era and beyond</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">79</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Quantum supremacy using a programmable superconducting processor</title>
		<author>
			<persName><forename type="first">F</forename><surname>Arute</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-019-1666-5</idno>
	</analytic>
	<monogr>
		<title level="j">Nature (London)</title>
		<imprint>
			<biblScope unit="volume">574</biblScope>
			<biblScope unit="page">505</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Charge-insensitive qubit design derived from the Cooper pair box</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gambetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Houck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Majer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Devoret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Girvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Schoelkopf</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.76.042319</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. A</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">42319</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gate-error analysis in simulations of quantum computers with transmon qubits</title>
		<author>
			<persName><forename type="first">D</forename><surname>Willsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nocon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">De</forename><surname>Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Michielsen</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.96.062302</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. A</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page">62302</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Berke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Varvelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Trebst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Altland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Divincenzo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05923</idno>
		<title level="m">Transmon platform for quantum computing challenged by chaotic fluctuations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An introduction to quantum error correction and fault-tolerant quantum computation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gottesman</surname></persName>
		</author>
		<idno type="DOI">10.1090/psapm/068/2762145</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Symp. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fault-tolerant quantum computation by anyons</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Kitaev</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0003-4916(02)00018-0</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Phys. (Amsterdam)</title>
		<imprint>
			<biblScope unit="volume">303</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Bravyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Kitaev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:quant-ph/9811052</idno>
		<title level="m">Quantum codes on a lattice with boundary</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Surface codes: Toward practical large-scale quantum computation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mariantoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Cleland</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.86.032324</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. A</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page">32324</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Repeated quantum error detection in a surface code</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Remm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krinner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabureac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eichler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wallraff</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41567-020-0920-y</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Phys</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">875</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Stabilizer codes and quantum error correction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gottesman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Path, trees, and flowers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Edmonds</surname></persName>
		</author>
		<idno type="DOI">10.4153/CJM-1965-045-4</idno>
	</analytic>
	<monogr>
		<title level="j">Can. J. Math</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">449</biblScope>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Topological quantum memory</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Landahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.1499754</idno>
	</analytic>
	<monogr>
		<title level="j">J. Math. Phys. (N.Y.)</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">4452</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Analysis of quantum error-correcting codes: Symplectic lattice codes and toric codes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Harrington</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast Decoders for Topological Quantum Codes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Duclos-Cianci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poulin</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.104.050504</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">50504</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Duclos-Cianci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poulin</surname></persName>
		</author>
		<title level="m">2010 IEEE Information Theory Workshop</title>
		<meeting><address><addrLine>Dublin</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fault-tolerant renormalization group decoder for abelian topological codes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Duclos-Cianci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poulin</surname></persName>
		</author>
		<idno type="DOI">10.26421/QIC14.9-10-1</idno>
	</analytic>
	<monogr>
		<title level="j">Quantum Inf. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">721</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Almost-linear time decoding algorithm for topological codes</title>
		<author>
			<persName><forename type="first">N</forename><surname>Delfosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Nickerson</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2021-12-02-595</idno>
	</analytic>
	<monogr>
		<title level="j">Quantum</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">595</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The prefactor αðL 2 Þ is the inverse of Ackermann&apos;s function whose value is &lt; 3 for all practical purposes</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Decoding small surface codes with feedforward neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Varsamopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Criger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bertels</surname></persName>
		</author>
		<idno type="DOI">10.1088/2058-9565/aa955a</idno>
	</analytic>
	<monogr>
		<title level="j">Quantum Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">15004</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural Decoder for Topological Codes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Torlai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Melko</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.119.030501</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">30501</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep neural network probabilistic decoder for stabilizer codes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Krastanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-017-11266-1</idno>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11003</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The bottom panels show comparisons with the bare UF decoder on a log-log scale. Shown is the average decoding time measured in wall clock time averaged over 10 6 error instances. The &quot;kernel adjusted&quot; time in the lower panels is the ML þ UF decoding time subtracted by a constant offset, to compensate kernel launch times (see main text)</title>
		<author>
			<persName><surname>Fig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PHYSICAL REVIEW LETTERS</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page">80505</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Algorithmic scaling of our hierarchical decoder for various rates of depolarizing noise (top panel)</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep neural decoders for near term fault-tolerant experiments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chamberland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ronagh</surname></persName>
		</author>
		<idno type="DOI">10.1088/2058-9565/aad1f7</idno>
	</analytic>
	<monogr>
		<title level="j">Quantum Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">44002</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural network decoder for topological color codes with circuit level noise</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baireuther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Caio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Criger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Beenakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>O'brien</surname></persName>
		</author>
		<idno type="DOI">10.1088/1367-2630/aaf29e</idno>
	</analytic>
	<monogr>
		<title level="j">New J. Phys</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">13003</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural Belief-Propagation Decoders for Quantum Error-Correcting Codes</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poulin</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.122.200501</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page">200501</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Quantum error correction for the toric code using deep reinforcement learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Andreasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liljestrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Granath</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2019-09-02-183</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">183</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Symmetries for a high-level neural decoder on the toric code</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kampermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bruß</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.102.042411</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. A</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page">42411</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep Q-learning decoder for depolarizing noise on the toric code</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fitzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eliasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Kockum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Granath</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevResearch.2.023230</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">23230</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reinforcement learning for optimal error correction of toric codes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Domingo Colomer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skotiniotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muñoz-Tapia</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physleta.2020.126353</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. A</title>
		<imprint>
			<biblScope unit="volume">384</biblScope>
			<biblScope unit="page">126353</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<author>
			<persName><forename type="first">X</forename><surname>Ni</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2020-08-24-310</idno>
	</analytic>
	<monogr>
		<title level="m">Neural network decoders for large-distance 2D toric codes</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">310</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Determination of the semion code threshold using neural decoders</title>
		<author>
			<persName><forename type="first">S</forename><surname>Varona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Martin-Delgado</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.102.032411</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. A</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page">32411</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reinforcement learning decoders for fault-tolerant quantum computation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sweke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Kesselring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P L</forename><surname>Van Nieuwenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eisert</surname></persName>
		</author>
		<idno type="DOI">10.1088/2632-2153/abc609</idno>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">25005</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Delfosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.11427</idno>
		<title level="m">Hierarchical decoding to reduce hardware requirements for quantum computing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">35-41], for a detailed overview of ML-based decoders, a more detailed description of the neural network, MWPM, and UF</title>
		<idno type="DOI">10.1103/PhysRevLett.128.080505</idno>
		<ptr target="http://link.aps.org/supplemental/10.1103/PhysRevLett.128.080505" />
		<imprint/>
	</monogr>
	<note>See Supplemental Material. which includes Refs. as well as a comparison to other decoding algorithms</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Pattison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carmean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Delfosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.06598</idno>
		<title level="m">A scalable decoder microarchitecture for fault-tolerant quantum computing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<title level="m">Proceedings of the 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><surname>Tensorflow</surname></persName>
		</author>
		<ptr target="https://github.com/tensorflow/tensorflow" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Implementation of algorithms for maximum matching on nonbipartite graphs</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Gabow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Ph. D. thesis</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawler</surname></persName>
		</author>
		<title level="m">Combinatorial Optimization: Networks and Matroids</title>
		<meeting><address><addrLine>Holt, Rinehart, and Winston</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Toward Practical Classical Processing for the Surface Code</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Whiteside</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C L</forename><surname>Hollenberg</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.108.180501</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">180501</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Linear-time maximum likelihood decoding of surface codes over the quantum erasure channel</title>
		<author>
			<persName><forename type="first">N</forename><surname>Delfosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zémor</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevResearch.2.033042</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">33042</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Meinerz</surname></persName>
		</author>
		<ptr target="https://github.com/chaeyeun-park/UnionFind" />
		<title level="m">Open-source C++ implementation of the Union-Find decoder</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">O</forename><surname>Higgott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Breuckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pymatching</forename></persName>
		</author>
		<ptr target="https://pymatching.readthedocs.io/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Subsystem Codes with High Thresholds by Gauge Fixing and Reduced Qubit Overhead</title>
		<author>
			<persName><forename type="first">O</forename><surname>Higgott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Breuckmann</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevX.11.031039</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. X</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">31039</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">One can push the threshold value even further up (at the expense of additional compute time) by employing a larger 7 × 7 subsystem, which gives p th ¼ 0.167ð0Þ (see also Table I)</title>
		<imprint/>
	</monogr>
	<note>Going to even larger subsystems has not. resulted in any further notable improvement of the threshold value</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Strong Resilience of Topological Codes to Depolarization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bombin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Andrist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ohzeki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Katzgraber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Martin-Delgado</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevX.2.021004</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. X</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">21004</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
